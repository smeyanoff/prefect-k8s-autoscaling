# ETL pipeline

## Description

Шаблон для выполнения spark applications, используя Prefect.

Шаблон уже настроен таким образом, чтобы количество изменений, которые должен выполнить разработчик, было минимальным.

В `src/application` находится основной файл спарк приложения. Это основной исполняемый файл, который нужно изменять.
В `src/flows` находится основной flow, который запускает spark приложение. В большинстве случаев менять его не нужно.
В `src/mainfests` находятся манифесты спарк приложения. `spark_based.yaml` можно изменять под конкретный application. Вы можете поменять количество ресурсов для драйвера и экзекьюторов. Если необходим очень производительный конфиг, необходимо поменять affinity и toletetions секции (прим. значения `values`). Более подробно можно прочитать в пункте Resources.
В `src/config.py` находится конфиг приложения. В большинстве случаев менять его не нужно. Однако, может понадобится добавить переменные окружения для spark приложения.

Заметки:
1. Любые изменения, касающиеся конфига `spark_application.yaml`, должны производиться через taskи Prefect (и следовательно являться переменными flow/параметрами деплоймента) для удобства настройки CI/CD. Здесь имеются ввиду `parameters` секция в `prefect.yaml`.
2. Переменные окружения, которые нужны в контейнерах spark для исполнения `spark_application.py`, можно передать в контейнер с помощью `src/config.py`.
3. Для CI `DEPLOYMENT_TAG` -- это версия, которая берется из pyproject.toml. Если не поменять версию, то не получится смерджить ветки в CI, так как JOB просто не появится.

#### Справка по версиям
Версия состоит из трех цифр разделенных точкой `0.1.0`

Первая цифра -- Мажорная версия, которая говорит о качественных изменениях и не гарантирует обратную совместимость.
Вторая цифра -- Минорная версия, добавление новой функциональности.
Третья цифра -- Патч, устранение багов и мелкие правки существующей функциональности

При разработке и тестировании может возникнуть необходимость тестировать функциональность в тестовой среде Prefect. Тогда версию можно указывать в `.env` файле. Чтобы не перегружать версионирование патчами при дебаггинге, нужно добавить к версии `-rc1, -rc2, ...` в зависимости от патча.
Тогда версия в `.env` будет выглядеть так - `0.1.0-rc1, 0.1.0-rc2 и т.д.`.

#### Про GitOps подход
При мердже в ветки `test` и `main` в удаленном репозитории запускается CI/CD процесс, который деплоит флоу в определенный work pool.
Ветки репозитория названы также, как и work pool'ы в prefect. Таким образом при мердже в тест, флоу деплоится в `test work pool`, при мердже в мейн - в `main`.
Весь CI описан в `.gitlab-ci.yml`.

## Resources
Подробнее про ограничение ресурсов можно прочитать в нашем [wiki](https://wiki.yandex.ru/ons-home/servisy/spark/ogranichenie-resursov/)

## Prerequisites
Чтобы запустить локально, необходимы следующие пакеты:

- make
- python (see version in pyproject.toml)

## Makefile
Чтобы вызвать справку по Makefile `make help`

В Makefile можно найти полезные команды по инициализации проекта и установке зависимостей, линтерам, тестировании и деплое.
